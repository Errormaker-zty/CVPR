{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:37.327388Z",
     "start_time": "2023-05-13T00:11:25.028179Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2A0v-mxcq2X0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:39.733116Z",
     "start_time": "2023-05-13T00:11:39.726149Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "W0-mzjT7q-_m"
   },
   "outputs": [],
   "source": [
    "def is_same(im1, im2, eps=0.01):\n",
    "    return np.sum(np.abs(im1 - im2) / np.prod(im1.shape)) <= eps\n",
    "\n",
    "def print_res_match(im1, im2, eps=0.01):\n",
    "    print('Result Match = ' + str(is_same(im1, im2, eps)))\n",
    "\n",
    "def print_shape_match(im1, im2):\n",
    "    print('Shape Match = ' + str(im1.shape == im2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:47.759314Z",
     "start_time": "2023-05-13T00:11:47.143623Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "M8WtOv28rEd7"
   },
   "outputs": [],
   "source": [
    "# import the reference code (master solution)\n",
    "# and the student's code\n",
    "student = __import__('pylayer')# if len(sys.argv) == 1 else sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:50.870242Z",
     "start_time": "2023-05-13T00:11:50.768915Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fVehk-TNrIcx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Conv2d:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing Conv2d:')\n",
    "# initialize Conv2d\n",
    "student_conv = student.Conv2d(3, 6, kernel_size=3, stride=2, padding=1)\n",
    "ref_conv = nn.Conv2d(3, 6, kernel_size=3, stride=2, padding=1, bias=True)\n",
    "# align input data\n",
    "conv_data_pt = Variable(torch.rand(1, 3, 32, 32), requires_grad = True)\n",
    "conv_data_numpy = conv_data_pt.data.numpy()\n",
    "# align weight and bias\n",
    "ref_conv.weight.data = torch.from_numpy(student_conv.weight).clone().detach().requires_grad_(True)\n",
    "ref_conv.bias.data = torch.from_numpy(student_conv.bias).clone().detach().requires_grad_(True)\n",
    "# check output\n",
    "ref_out = ref_conv(conv_data_pt)\n",
    "student_out = student_conv.forward(conv_data_numpy)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out, grad_w, grad_b = student_conv.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(conv_data_pt.grad.data.numpy(), grad_out)\n",
    "print_res_match(ref_conv.weight.grad.data.numpy(), grad_w)\n",
    "print_res_match(ref_conv.bias.grad.data.numpy(), grad_b)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:54.195961Z",
     "start_time": "2023-05-13T00:11:54.163493Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "tkHBQ7_DrSN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "\n",
      "\n",
      "Testing MaxPool2d:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing Linear:')\n",
    "# initialize Linear\n",
    "student_linear = student.Linear(30, 10)\n",
    "ref_linear = nn.Linear(30, 10, bias=True)\n",
    "# align input data\n",
    "linear_data_pt = Variable(torch.rand(1, 30), requires_grad = True)\n",
    "linear_data_numpy = linear_data_pt.data.numpy()\n",
    "# align weight and bias\n",
    "# NOTE: Use transpose is because the slight shape definition difference between PyNet and Pytorch.\n",
    "ref_linear.weight.data = torch.from_numpy(student_linear.weight.transpose().astype(np.float32)).clone().detach().requires_grad_(True)\n",
    "ref_linear.bias.data = torch.from_numpy(student_linear.bias.transpose().astype(np.float32)).clone().detach().requires_grad_(True)\n",
    "# check output\n",
    "ref_out = ref_linear(linear_data_pt)\n",
    "student_out = student_linear.forward(linear_data_numpy)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out, grad_w, grad_b = student_linear.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(linear_data_pt.grad.data.numpy(), grad_out)\n",
    "print_res_match(ref_linear.weight.grad.data.numpy().transpose(), grad_w)\n",
    "print_res_match(ref_linear.bias.grad.data.numpy().transpose(), grad_b)\n",
    "print('\\n')\n",
    "\n",
    "print('Testing MaxPool2d:')\n",
    "# initialize Linear\n",
    "student_maxpool = student.MaxPool2d(kernel_size=2, stride=2)\n",
    "ref_maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "# align input data\n",
    "maxpool_data_pt = Variable(torch.rand(1, 3, 32, 32), requires_grad = True)\n",
    "maxpool_data_numpy = maxpool_data_pt.data.numpy()\n",
    "# check output\n",
    "ref_out = ref_maxpool(maxpool_data_pt)\n",
    "student_out = student_maxpool.forward(maxpool_data_numpy)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out = student_maxpool.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(maxpool_data_pt.grad.data.numpy(), grad_out)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:57.476307Z",
     "start_time": "2023-05-13T00:11:57.453366Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SPIu4t1GrXyp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ReLU:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing ReLU:')\n",
    "# initialize Relu\n",
    "student_relu = student.ReLU()\n",
    "ref_relu = nn.ReLU()\n",
    "# align input data\n",
    "relu_data_pt = Variable(torch.rand(1, 3, 32, 32), requires_grad = True)\n",
    "relu_data_numpy = relu_data_pt.data.numpy()\n",
    "# check output\n",
    "ref_out = ref_relu(relu_data_pt)\n",
    "student_out = student_relu.forward(relu_data_numpy)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out = student_relu.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(relu_data_pt.grad.data.numpy(), grad_out)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:11:59.964760Z",
     "start_time": "2023-05-13T00:11:59.941737Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lpLH6Lyvrd7E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BatchNorm1d:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing BatchNorm1d:')\n",
    "# initialize BN\n",
    "student_bn = student.BatchNorm1d(100)\n",
    "ref_bn = nn.BatchNorm1d(100)\n",
    "# align input data\n",
    "bn_data_pt = Variable(torch.rand(20, 100), requires_grad = True)\n",
    "bn_data_numpy = bn_data_pt.data.numpy()\n",
    "# align BN params\n",
    "ref_bn.weight.data = torch.from_numpy(student_bn.gamma).clone().detach().requires_grad_(True)\n",
    "ref_bn.bias.data = torch.from_numpy(student_bn.beta).clone().detach().requires_grad_(True)\n",
    "ref_bn.running_mean.data = torch.from_numpy(student_bn.r_mean).clone().detach().requires_grad_(False)\n",
    "ref_bn.running_var.data = torch.from_numpy(student_bn.r_var).clone().detach().requires_grad_(False)\n",
    "ref_bn.momentum = student_bn.momentum\n",
    "ref_bn.eps = student_bn.eps\n",
    "# check output\n",
    "ref_out = ref_bn(bn_data_pt)\n",
    "student_out = student_bn.forward(bn_data_numpy, train=True)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out, grad_gamma, grad_beta = student_bn.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(bn_data_pt.grad.data.numpy(), grad_out)\n",
    "print_res_match(ref_bn.weight.grad.data.numpy(), grad_gamma)\n",
    "print_res_match(ref_bn.bias.grad.data.numpy(), grad_beta)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-13T00:12:01.627964Z",
     "start_time": "2023-05-13T00:12:01.606047Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qZbQTzVHrgkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing cross_entropy_loss_with_softmax:\n",
      "Shape Match = True\n",
      "Result Match = True\n",
      "Result Match = True\n"
     ]
    }
   ],
   "source": [
    "print('Testing cross_entropy_loss_with_softmax:')\n",
    "# initialize cross_entropy loss\n",
    "# Note: PyNet's cross_entropy loss functions as Pytorch\n",
    "# CrossEntropyLoss when reduction='none', So the output loss shape as well\n",
    "# as the gradients shape are N*C shape.\n",
    "student_loss = student.CrossEntropyLossWithSoftmax()\n",
    "ref_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "# align input data\n",
    "loss_data_pt = torch.randn(3, 5, requires_grad = True)\n",
    "loss_data_numpy = loss_data_pt.data.numpy()\n",
    "# align target data\n",
    "loss_target_pt = torch.empty(3, dtype=torch.long).random_(5)\n",
    "loss_target_numpy = loss_target_pt.data.numpy()\n",
    "# check output\n",
    "ref_out = ref_loss(loss_data_pt, loss_target_pt)\n",
    "student_out = student_loss.forward(loss_data_numpy, loss_target_numpy)\n",
    "print_shape_match(ref_out.data.numpy(), student_out)\n",
    "print_res_match(ref_out.data.numpy(), student_out)\n",
    "# check gradients\n",
    "grad_out = student_loss.backward(np.ones_like(student_out))\n",
    "ref_out.backward(torch.ones_like(ref_out))\n",
    "print_res_match(loss_data_pt.grad.data.numpy(), grad_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "gradient_check.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
